## Information bottleneck theory for deep learning

[![Render in nbviewer](https://github.com/jupyter/design/blob/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.jupyter.org/github/stevenliuyi/information-bottleneck/blob/master/information_bottleneck.ipynb)

This repository contains a Jupyter notebook, in which I built a very simple neural network to demonstrate the [information bottleneck theory](https://en.wikipedia.org/wiki/Information_bottleneck_method) for deep learning proposed by Naftali Tishby. The information bottleneck method is based on information theory. It was first introduced in 1999, and was recently applied to deep neural networks as an attempt to look inside the black box of deep learning.

For more information about the theory, please refer to [their paper](https://arxiv.org/pdf/1703.00810.pdf) or [this talk on Youtube](https://www.youtube.com/watch?v=bLqJHjXihK8). [This article](https://www.quantamagazine.org/new-theory-cracks-open-the-black-box-of-deep-learning-20170921/) on the Quanta Magazine also contains very useful information.
